{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.67      0.55      0.60        11\n",
      "        PwPD       0.38      0.50      0.43         6\n",
      "\n",
      "    accuracy                           0.53        17\n",
      "   macro avg       0.52      0.52      0.51        17\n",
      "weighted avg       0.56      0.53      0.54        17\n",
      "\n",
      "RFC Confusion Matrix:\n",
      "[[6 5]\n",
      " [3 3]]\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       1.00      0.09      0.17        11\n",
      "        PwPD       0.38      1.00      0.55         6\n",
      "\n",
      "    accuracy                           0.41        17\n",
      "   macro avg       0.69      0.55      0.36        17\n",
      "weighted avg       0.78      0.41      0.30        17\n",
      "\n",
      "SVM Confusion Matrix:\n",
      "[[ 1 10]\n",
      " [ 0  6]]\n",
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.71      0.45      0.56        11\n",
      "        PwPD       0.40      0.67      0.50         6\n",
      "\n",
      "    accuracy                           0.53        17\n",
      "   macro avg       0.56      0.56      0.53        17\n",
      "weighted avg       0.60      0.53      0.54        17\n",
      "\n",
      "KNN Confusion Matrix:\n",
      "[[5 6]\n",
      " [2 4]]\n",
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.3999 - loss: 2.6961 - val_accuracy: 0.3529 - val_loss: 1.8853\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4231 - loss: 1.3321 - val_accuracy: 0.6471 - val_loss: 1.3881\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4966 - loss: 1.9521 - val_accuracy: 0.6471 - val_loss: 0.7253\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6194 - loss: 0.7108 - val_accuracy: 0.4118 - val_loss: 1.6524\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5581 - loss: 0.9745 - val_accuracy: 0.4118 - val_loss: 1.1190\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6502 - loss: 0.6680 - val_accuracy: 0.3529 - val_loss: 0.8402\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7003 - loss: 0.6413 - val_accuracy: 0.7059 - val_loss: 0.8281\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6307 - loss: 0.7267 - val_accuracy: 0.2941 - val_loss: 1.0962\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7079 - loss: 0.5729 - val_accuracy: 0.3529 - val_loss: 0.9865\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7037 - loss: 0.5558 - val_accuracy: 0.6471 - val_loss: 0.9620\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\S M N RAZA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\S M N RAZA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\S M N RAZA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79        11\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.65        17\n",
      "   macro avg       0.32      0.50      0.39        17\n",
      "weighted avg       0.42      0.65      0.51        17\n",
      "\n",
      "CNN Confusion Matrix:\n",
      "[[11  0]\n",
      " [ 6  0]]\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipywidgets import Dropdown, Button, Output, VBox\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n",
    "from tensorflow.keras import layers, models\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import time\n",
    "import tempfile\n",
    "\n",
    "# Function to display the available files in the directory\n",
    "def list_audio_files(directory):\n",
    "    return [file for file in os.listdir(directory) if file.endswith('.wav')]\n",
    "\n",
    "# Feature extraction function with labeled MFCCs\n",
    "def feature_extraction(file_path):\n",
    "    \"\"\"Extracts MFCC features from an audio file.\"\"\"\n",
    "    # Load the audio file\n",
    "    x, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "    \n",
    "    # Extract MFCC features (22 coefficients)\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=x, sr=sample_rate, n_mfcc=22).T, axis=0)\n",
    "    \n",
    "    # Label MFCC features (MFCC Coefficient 1, MFCC Coefficient 2, etc.)\n",
    "    mfcc_labels = [f'MFCC_Coefficient_{i+1}' for i in range(len(mfcc))]\n",
    "    return mfcc, mfcc_labels\n",
    "\n",
    "# Directories containing the audio files for Healthy Controls and PwPD\n",
    "hc_directory = r'C:\\Users\\S M N RAZA\\Downloads\\HC_AH1\\HC_AH'   # Update with your HC directory path\n",
    "pwpd_directory = r'C:\\Users\\S M N RAZA\\Downloads\\PD_AH1\\PD_AH'     # Update with your PwPD directory path\n",
    "\n",
    "# List all audio files in both directories\n",
    "hc_audio_files = list_audio_files(hc_directory)\n",
    "pwpd_audio_files = list_audio_files(pwpd_directory)\n",
    "\n",
    "# Create an empty DataFrame to store all MFCC features\n",
    "mfcc_df = pd.DataFrame()\n",
    "\n",
    "# Extract features from Healthy Controls\n",
    "for audio_file in hc_audio_files:\n",
    "    audio_path = os.path.join(hc_directory, audio_file)\n",
    "    mfcc_features, mfcc_labels = feature_extraction(audio_path)\n",
    "    temp_df = pd.DataFrame(mfcc_features.reshape(1, -1), columns=mfcc_labels)\n",
    "    temp_df['Audio_File'] = audio_file\n",
    "    temp_df['Label'] = 'HC' \n",
    "    mfcc_df = pd.concat([mfcc_df, temp_df], ignore_index=True)\n",
    "\n",
    "# Extract features from PwPD\n",
    "for audio_file in pwpd_audio_files:\n",
    "    audio_path = os.path.join(pwpd_directory, audio_file)\n",
    "    mfcc_features, mfcc_labels = feature_extraction(audio_path)\n",
    "    temp_df = pd.DataFrame(mfcc_features.reshape(1, -1), columns=mfcc_labels)\n",
    "    temp_df['Audio_File'] = audio_file\n",
    "    temp_df['Label'] = 'PwPD'  \n",
    "    mfcc_df = pd.concat([mfcc_df, temp_df], ignore_index=True)\n",
    "\n",
    "# Prepare data for model training\n",
    "X = mfcc_df.drop(columns=['Audio_File', 'Label'])\n",
    "y = mfcc_df['Label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rfc_model = RandomForestClassifier(random_state=42)\n",
    "rfc_model.fit(X_train, y_train)\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "svm_model = SVC(probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Initialize and train the KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with all models\n",
    "rfc_pred = rfc_model.predict(X_test)\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Print classification reports and confusion matrices\n",
    "print(\"RFC Classification Report:\")\n",
    "print(classification_report(y_test, rfc_pred))\n",
    "\n",
    "print(\"RFC Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, rfc_pred))\n",
    "\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, svm_pred))\n",
    "\n",
    "print(\"SVM Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, svm_pred))\n",
    "\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, knn_pred))\n",
    "\n",
    "print(\"KNN Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, knn_pred))\n",
    "\n",
    "# Save the trained models\n",
    "joblib.dump(rfc_model, 'rfc_trained_model.joblib')\n",
    "joblib.dump(svm_model, 'svm_trained_model.joblib')\n",
    "joblib.dump(knn_model, 'knn_trained_model.joblib')\n",
    "\n",
    "# Prepare data for CNN\n",
    "X_cnn = X.values.reshape(X.shape[0], X.shape[1], 1)\n",
    "X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(X_cnn, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "def build_cnn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    model.add(layers.Conv1D(32, kernel_size=3, activation='relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    model.add(layers.Conv1D(64, kernel_size=3, activation='relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "cnn_model = build_cnn_model((X_train_cnn.shape[1], 1))\n",
    "cnn_model.fit(X_train_cnn, y_train_cnn.map({'HC': 0, 'PwPD': 1}).values, epochs=10, batch_size=32, validation_data=(X_test_cnn, y_test_cnn.map({'HC': 0, 'PwPD': 1}).values))\n",
    "\n",
    "\n",
    "y_pred_cnn = (cnn_model.predict(X_test_cnn) > 0.5).astype(\"int32\").reshape(-1)\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(y_test_cnn.map({'HC': 0, 'PwPD': 1}), y_pred_cnn))\n",
    "print(\"CNN Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_cnn.map({'HC': 0, 'PwPD': 1}), y_pred_cnn))\n",
    "\n",
    "\n",
    "cnn_model.save('cnn_parkinsons_model.h5')\n",
    "\n",
    "\n",
    "def display_audio_and_classify(audio_file, directory):\n",
    "    audio_path = os.path.join(directory, audio_file)\n",
    "    print(f\"Playing: {audio_file}\")\n",
    "    ipd.display(ipd.Audio(audio_path))\n",
    "    \n",
    "    mfcc_features, mfcc_labels = feature_extraction(audio_path)\n",
    "    mfcc_df_single = pd.DataFrame(mfcc_features.reshape(1, -1), columns=mfcc_labels)\n",
    "    \n",
    "    rfc_prediction = rfc_model.predict(mfcc_df_single)[0]\n",
    "    svm_prediction = svm_model.predict(mfcc_df_single)[0]\n",
    "    knn_prediction = knn_model.predict(mfcc_df_single)[0]\n",
    "    cnn_prediction = (cnn_model.predict(mfcc_df_single.values.reshape(1, -1, 1)) > 0.5).astype(\"int32\")[0][0]\n",
    "\n",
    "    print(f\"Random Forest Prediction for {audio_file}: {'Parkinson Disease (PwPD)' if rfc_prediction == 'PwPD' else 'Healthy Control (HC)'}\")\n",
    "    print(f\"SVM Prediction for {audio_file}: {'Parkinson Disease (PwPD)' if svm_prediction == 'PwPD' else 'Healthy Control (HC)'}\")\n",
    "    print(f\"KNN Prediction for {audio_file}: {'Parkinson Disease (PwPD)' if knn_prediction == 'PwPD' else 'Healthy Control (HC)'}\")\n",
    "    print(f\"CNN Prediction for {audio_file}: {'Parkinson Disease (PwPD)' if cnn_prediction == 1 else 'Healthy Control'}\")\n",
    "\n",
    "\n",
    "audio_dropdown = Dropdown(\n",
    "    options=hc_audio_files + pwpd_audio_files,\n",
    "    description='Select Audio:'\n",
    ")\n",
    "classify_button = Button(description='Classify')\n",
    "output = Output()\n",
    "\n",
    "# Function to record live audio \n",
    "def record_audio(duration=5, sample_rate=22050):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)\n",
    "    sd.wait()  # Wait until the recording is finished\n",
    "    print(\"Recording complete.\")\n",
    "    \n",
    "    # Save the audio to a temporary file\n",
    "    temp_file = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
    "    write(temp_file.name, sample_rate, audio)  # Save as .wav file\n",
    "    return temp_file.name\n",
    "\n",
    "# Button to capture live audio and classify it\n",
    "record_button = Button(description=\"Record and Classify Live Audio\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99c825c0fb2467f8e94c04747a525f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Select Audio:', options=('AH_064F_7AB034C9-72E4-438B-A9B3-AD7FDA1596C5.wa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Button click \n",
    "def on_classify_button_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        selected_audio = audio_dropdown.value\n",
    "        directory = hc_directory if selected_audio in hc_audio_files else pwpd_directory\n",
    "        display_audio_and_classify(selected_audio, directory)\n",
    "\n",
    "# Button click \n",
    "def on_record_button_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        temp_file_path = record_audio(duration=5)  # Record 5 seconds of audio\n",
    "        print(\"Classifying recorded audio...\")\n",
    "        display_audio_and_classify(temp_file_path, os.path.dirname(temp_file_path))\n",
    "\n",
    "# Bind the button \n",
    "classify_button.on_click(on_classify_button_clicked)\n",
    "record_button.on_click(on_record_button_clicked)\n",
    "\n",
    "# Display the widgets\n",
    "display(VBox([audio_dropdown, classify_button, record_button, output]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
